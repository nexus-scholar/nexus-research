# Simple SLR Configuration File
# =================================

# Global Settings
# ----------------
# Email address used for polite API requests (highly recommended)
# This allows providers to contact you if your scripts are causing issues
# and often grants higher rate limits (e.g., OpenAlex, Crossref).
mailto: "bekhouche.mouadh@univ-oeb.dz"

# Default year range for all queries (can be overridden per query)
year_min: 2024
year_max: 2026

# Default language filter (ISO 639-1 code)
language: "en"

# Provider Configuration
# -----------------------
# Enable/disable specific academic databases and configure their rate limits.
providers:
  openalex:
    enabled: true
    rate_limit: 5.0  # Requests per second (polite pool)
    timeout: 30      # Request timeout in seconds

  crossref:
    enabled: true
    rate_limit: 1.0  # Conservative default
    timeout: 30

  arxiv:
    enabled: true
    rate_limit: 0.5  # Recommended: 3 seconds per request
    timeout: 30

  # Semantic Scholar (alias: s2)
  # Requires API key for higher rate limits, otherwise very restricted
  s2:
    enabled: true
    rate_limit: 1.0

  pubmed:
    enabled: true
    rate_limit: 3.0

  doaj:
    enabled: true
    rate_limit: 2.0

  core:
    enabled: true
    api_key: "lzcWJVBjnaqfP5rbHowhYGmZ2X8xEiSt"
    rate_limit: 1.0

  ieee:
    enabled: true
    api_key: "sbtnjtg89w6m2hvk6rutt9wb"
    rate_limit: 1.0

# Deduplication Settings
# -----------------------
deduplication:
  # Strategy: 'conservative' (exact match + strict title), 'semantic' (embeddings), 'hybrid'
  # Note: 'semantic' and 'hybrid' require additional dependencies.
  strategy: "conservative"

  # Fuzzy matching threshold (0-100) for title similarity in conservative mode
  fuzzy_threshold: 97

  # Maximum allowed year difference between potential duplicates
  max_year_gap: 1

# Screener Heuristics
# -------------------
# These lists are used by the layered screener's heuristic pre-filter.
screener:
  # If include_groups is set, a document must match at least one term from each group.
  include_groups:
    - [
        "plant", "leaf", "crop", "fruit", "disease", "leaf spot", "rust",
        "mildew", "blight", "wilt", "tomato", "rice", "wheat", "maize",
        "banana", "grape", "apple", "potato"
      ]
    - [
        "deep learning", "cnn", "vgg", "resnet", "densenet", "efficientnet",
        "mobilenet", "convnext", "transformer", "vit", "swin", "yolo",
        "yolov8", "segmentation", "mask r-cnn", "graph neural network",
        "attention", "few-shot", "meta-learning", "self-supervised",
        "semi-supervised", "self-training", "representation learning",
        "transfer learning", "pruning", "quantization", "lightweight",
        "edge", "gan", "diffusion", "data augmentation"
      ]
  # Used only when include_groups is empty.
  include_patterns: []
  exclude_patterns:
    - "weed detection"
    - "weed control"
    - "pest detection"
    - "pest control"
    - "pest infestation"
    - "insect pest"
    - "aphid"
    - "aphids"
    - "virus detection"
    - "remote sensing"
    - "hyperspectral imaging"
    - "hyperspectral"
    - "satellite"
    - "uav"
    - "drone"
    - "aerial"
    - "yield prediction"
  # Optional per-layer model names; last one is reused for remaining layers.
  models: []

# Full-Text Extraction
# --------------------
full_text_extraction:
  schema_path: "full_text_extraction_schema.yaml"
  max_tokens: 6000
  section_priority:
    - methods
    - results
    - discussion
    - introduction
    - abstract
    - related_work
    - conclusion
  include_tables: true
  model: "gpt-4o"
  group_models:
    group1_context: "gpt-5-nano"
    group2_data: "gpt-5-nano"
    group3_models: "gpt-5-nano"
    group4_eval: "gpt-4o"
  group_clients:
    group1_context:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY"
    group2_data:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY"
    group3_models:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY"
    group4_eval:
      base_url: "https://api.openai.com/v1"
      api_key_env: "OPENAI_API_KEY"
  group_fields: {}
  require_evidence: false
  batch_size: 3
  resume: true
  log_prompts: false

# Output Configuration
# ---------------------
output:
  # Directory where results will be saved
  directory: "results/outputs"

  # Default output format: 'csv', 'jsonl', or 'both'
  format: "csv"

  # Include raw JSON response from providers in the output (increases file size)
  include_raw: true
